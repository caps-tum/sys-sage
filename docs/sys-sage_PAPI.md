# sys-sage PAPI

## General Information

The _sys-sage_ library incorporates the **P**erformance **A**pplication
**P**rogramming **I**nterface [[1]](#1) (PAPI) to enable the integration of
hardware performance counters on CPUs into the _sys-sage_ topology. That way,
the performance metrics gained through PAPI can be attributed directly to the
relevant hardware components, thus allowing for the examination and
interpretation of the performance metrics within the the context of the
hardware topology.

To enable this feature, use the `-DPAPI=on` flag when building the _sys-sage_
library. Apart from PAPI itself, note that `hwloc` is required as a dependency.
Please make sure that it's installed on your system and provide an XML file
generated by `hwloc`, which captures the hardware topology, to
`sys-sage::parseHwlocOutput`.

A link to the PAPI Wiki can be found [here](https://github.com/icl-utk-edu/papi/wiki).

## General Workflow

The following diagram shows the overall workflow of the PAPI metrics collection
and evaluation through _sys-sage_:

![](images/sys-sage_PAPI_workflow.png)

The green boxes correspond to the _sys-sage_ API whereas the blue ones
correspond to plain PAPI. In general, the creation and configuration of event
sets remain with PAPI, while the performance monitoring is now managed
through _sys-sage_.

## API overview

To realize the integration of PAPI into _sys-sage_, wrapper functions are
provided that envelop the underlying PAPI routine. They will be behave
**exactly** like the underlying PAPI routine, with the added logic of
automatically managing the storage of the performance counter values into
_sys-sage_. The wrapper functions are

| sys-sage wrapper | corresponding PAPI routine |
| ---------------- | -------------------------- |
| ```sys_sage::SS_PAPI_start``` | `PAPI_start` |
| ```sys_sage::SS_PAPI_reset``` | `PAPI_reset` |
| ```sys_sage::SS_PAPI_read``` | `PAPI_read` |
| ```sys_sage::SS_PAPI_accum``` | `PAPI_accum` |
| ```sys_sage::SS_PAPI_stop``` | `PAPI_stop` |

In general, the _sys-sage_ wrappers can coexist with plain PAPI and can
therefore be used next to the PAPI routines. This extends to routines like
`PAPI_create_eventset`, `PAPI_attach` and so on. However, the wrappers
`SS_PAPI_start`, `SS_PAPI_reset` and `SS_PAPI_accum` must be used instead of
`PAPI_start`, `PAPI_reset` and `PAPI_accum` respectively.

To access or display the performance metrics that are integrated into the
_sys-sage_ topology, the following functions are provided

| Routines to access & display PAPI metrics |
| ------------------------------------------- |
| ```sys_sage::Relation::GetPAPImetric``` |
| ```sys_sage::Relation::GetAllPAPImetrics``` |
| ```sys_sage::Relation::PrintAllPAPImetrics``` |
| ```sys_sage::Thread::GetPAPImetric``` |
| ```sys_sage::Thread::PrintAllPAPImetrics``` |

## Going through an Example

For more sophisticated examples, please have a look at the `examples/`
directory of the _sys-sage_ repository. The examples include

- `papi_basics.cpp`: Simple usage of _sys-sage_ PAPI
- `papi_multithreading.cpp`: Exploring multihreading in _sys-sage_ PAPI
- `papi_monitor_process.cpp`: Exploring third-party monitoring of another process in _sys-sage_ PAPI
- `papi_migrate_cpus.cpp`: Showcase of performance monitoring on a thread that constantly migrates across CPUs

A minimal example is provided below. Note that error handling has been left out
for the sake of simplicity and clarity. All _sys-sage_ PAPI wrappers have
adopted return error codes of PAPI. Please refer to PAPI's Wiki for the error
codes and to the documentation of the wrappers themselves for more information.

```cpp
sys_sage::Node *node = new sys_sage::Node;
sys_sage::parseHwlocOutput(node, path_to_hwloc_xml);

PAPI_library_init(PAPI_VER_CURRENT);

int eventSet = PAPI_NULL;
PAPI_create_eventset(&eventSet);
PAPI_add_event(eventSet, PAPI_TOT_INS);

sys_sage::Relation *metrics = nullptr;
sys_sage::SS_PAPI_start(eventSet, &metrics);

// do some computation...

sys_sage::SS_PAPI_stop(metrics, node);

metrics->PrintPAPImetrics();

PAPI_cleanup_eventset(eventSet);
PAPI_destroy_eventset(&eventSet);
PAPI_shutdown();
```

First, the _sys-sage_ topology is created by parsing the XML file that is
gained through hwloc. The `node` component then points to the root of the
topology. Afterwards, the PAPI library and an event set are initialized as
usual.

Now, in order to attribute the performance counter values to the hardware
components, the _sys-sage_ library uses a relation to naturally link them
together. For this purpose, a pointer of type `sys_sage::Relation` is provided
to `sys_sage::SS_PAPI_start`. Since the `metrics` is `nullptr`, the _sys-sage_
library will create a new relation object, to which `metrics` will point to
after the call to `sys_sage::SS_PAPI_start`. If it already points to a valid
relation object, that object will be reused instead. Within the same call, the
underlying `PAPI_start` routine will be used to start the event set.

After some computation, the wrapper `sys_sage::SS_PAPI_stop` is called to
stop the event set and to automatically integrate the performance counter
values into the topology. Information about the performance counter values and
the associated hardware components are then printed to `stdout`.

At the end, the event set is cleaned up and the PAPI library is shut down. Note
that the PAPI related functions offered in the _sys-sage_ API will not work if
the PAPI library is shut down.

## Under the Hood

The routines `sys_sage::SS_PAPI_read`, `sys_sage::SS_PAPI_accum` and
`sys_sage::SS_PAPI_stop` all follow a very similar strategy:

1. Based on the given event set, determine the events associated to it and
   store the event codes in a local array called `events`.

2. Perform the call to the underlying PAPI routine using a local array called
   `counters`.

   - `sys_sage::SS_PAPI_read`  -> `PAPI_read`

   - `sys_sage::SS_PAPI_accum` -> `PAPI_accum`

   - `sys_sage::SS_PAPI_stop`  -> `PAPI_stop`

3. Depending on the event set, figure out to which hardware thread the counters
   belong to and find its ID. Here, we need to make a case destinction:

   - If the event set has explicitely been attached to a hardware thread,
     simply query for the ID through PAPI.

   - If the event set has explicitely been attached to a software thread, get
     the last known hardware thread on which it was scheduled on by reading
     `/proc/<tid>/stat`.

   - Otherwise, the event set is implicitely attached to the current software
     thread, in which case we simply call `sched_getcpu()`.

   In the last two cases, the software thread can potentially migrate across
   multiple hardware threads through repeated re-scheduling. Since PAPI uses
   `perf_event_open` internally, the Linux kernel will preserve the
   intermediate performance counter values across context switches. To "keep
   track" of these hardware threads and to attribute the performance counter
   values to them, _sys-sage_ uses a new relation category named
   `RelationCategory::PAPI_Metrics`.

4. Together with the ID of the hardware thread, query for its handle in the
   _sys-sage_ topology. If the hardware thread is not already contained in the
   `Relation` object, it will be added to it.

5. Store the values of `counters` into the `attrib` map of the `Relation`
   object on a per-event basis, meaning that if the value `counters[i]` at
   index `i` corresponds to the event `events[i]`, we will have a key-value
   pair similar to `{ events[i], counters[i] }`. Note that the values are
   actually stored as entries of a datastructure and that the string
   representation of the event code is used as the actual key. This is a
   simplified overview and more detail is given below.

### Obtaining a `Relation` object

The user may gain access to a `Relation` object via the first call to the
`sys_sage::SS_PAPI_start` wrapper function. The usage can be described by the
following code snippet:

```cpp
// `metrics == nullptr` signals the sys-sage library to create a new `Relation`
// object of category `RelationCategory::PAPI_Metrics`
sys_sage::Relation *metrics = nullptr;

sys_sage::SS_PAPI_start(eventSet, &metrics);

// `metrics` points to a valid `Relation` object now

// do some performance monitoring...

// use plain PAPI to stop performance monitoring without caring for the values
PAPI_stop(eventSet, nullptr);

// do some performance analysis...

// reuse the `Relation` object
sys_sage::SS_PAPI_start(eventSet, &metrics);
```

Note that the `Relation` object is only bound to an event set between the calls
to  `sys_sage::SS_PAPI_start` and `sys_sage::SS_PAPI_stop`. It may be reused
again with a possible new configuration of the same event set or an entirely
new one.

### Multiple Performance Counter Readings

We define a "performance counter reading" to be the act of fetching the current
values of the performance counters. It may be triggered by a call to either
`sys_sage::SS_PAPI_read`, `sys_sage::SS_PAPI_accum` or `sys_sage::SS_PAPI_stop`.

Now, the _sys-sage_ library allows the user to store the results of multiple
performance counter readings of the same event. To distinguish them from one
another, timestamps have been introduced which are recorded into `*timestamp`.
A timestamp is always associated to the entire reading, meaning that
performance counter values of different events share the same timestamp within
the same reading. It is important to state that these timestamps are **not**
guaranteed to be unique for every reading -- although most likely they will --
and in case of a collision, the value of the latter reading will be returned.

### Accessing Performance Counter Values

Since Linux uses the term "CPU" in terms of a logical processing unit, we use
"CPU" and "hardware thread" interchangeable in the following.

The `RelationCategory::PAPI_Metrics` category of relations is able to
distinguish perf counter values of one CPU from another. The functions

```cpp
long long sys_sage::GetCpuPerfVal(const Relation *metrics, int event,
                                  int cpuNum = -1, unsigned long long timestamp = 0);

const sys_sage::CpuPerf *sys_sage::GetCpuPerf(const Relation *metrics, int event,
                                              int cpuNum);
```

are at the user's disposal for accessing the perf counter values corresponding
to a specific event.

The `sys_sage::GetCpuPerfVal` function both offers a CPU-centric view and an
EventSet-centric view. That is, if `cpuNum != -1`, the counter value of the
desired CPU will be returned. Otherwise, the values of all CPUs in the relation
will be combined into a single output, offering a EventSet-centric view which
would be equal to the value that plain PAPI would return. Furthermore, the
`timestamp` parameter may be used to filter out the perf counter value of a
specific perf counter reading. A value of 0 refers to the latest reading.

Moreover, the `sys_sage::GetCpuPerf` function returns a datastructure
containing all perf counter values of the corresponding CPU and event.

### Rules for the Storage Mechanism of the Performance Counter Values

For the purpose of simplicity, we will focus on single-event event sets in this
section. Everything described here can be easilly extended on to multiple events.

Let's define the operations _READ_, _RESET_ and _ACCUM_, which correspond to
the respective PAPI routines. We have

- _READ_: capture the perf current counter value and store it

- _RESET_: set the perf counter to 0

- _ACCUM_: capture the current value of the perf counter, add it to some data,
           and perform the _RESET_ operation

Furthermore, each entry of the datastructure containing the perf counter values
can be either in the _permanent_ or _temporary_ mode (indicated by the `permanent`
parameter). If an entry is temporary, it may be overwritten by some new perf
counter reading. If it is permanent, it may not be modified again, and
therefore a new entry must be added to the datastructure.

Now, the rules are as follows:

1. If a _READ_ operation supersedes a _RESET_ operation, all temporary entries
   of all CPUs of that specific event will be deleted.

2. If there are no more entries in the datastructure of a CPU, that CPU will
   be removed from the relation.

3. The value extracted from a _READ_ operation will be "split" among all CPUs
   whose latest entry is temporary and contains a value that stems from the
   latest reading.

If $x$ is the value gained from a _READ_ operation on CPU $a$ and $y$ is the
sum of values of all CPUs in the relation that satisfy the above conditions,
then the result $z := x - y$ is stored in an entry corresponding to CPU $a$.

4. The value extracted from an _ACCUM_ operation will be "merged" with all CPUs
   whose latest entry is permanent and contains a value that stems from the
   latest reading.

If $x$ is the value gained from an _ACCUM_ operation on CPU $a$ and $y$ is the
sum of values of all CPUs in the relation that satisfy the above conditions,
then the result $z := x + y$ is stored in an entry corresponding to CPU $a$.

## Error Handling

The error codes of PAPI have been adopted to maintain consistency.

## References

<a id="1">[1]</a>
Jagode H, Danalis A, Congiu G, Barry D, Castaldo A, Dongarra J.
**Advancements of PAPI for the exascale generation.**
_The International Journal of High Performance Computing Applications._
2024;39(2):251-268. [doi:10.1177/10943420241303884](https://journals.sagepub.com/doi/10.1177/10943420241303884)
